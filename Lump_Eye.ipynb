{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QvfEWNAyO3q-VRjA7b8LWd9GjDMggLvV",
      "authorship_tag": "ABX9TyPKeJZkPYs0Ak72B1Hg2pGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2001abdulrehman/FYP/blob/main/Lump_Eye.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING**"
      ],
      "metadata": {
        "id": "YQofD8P8l2hG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNWnMtiVdwEW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the data from the zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/lump eye/lump Train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('eye_images')"
      ],
      "metadata": {
        "id": "8fW7BKmne63O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the paths to your data\n",
        "train_dir = '/content/eye_images/Train'  # Update this path\n",
        "\n",
        "\n",
        "\n",
        "# Create an image data generator\n",
        "train_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,  # Adjust rotation range to simulate different lash angles\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness to highlight lashes\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_data_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Adjust the image size as needed\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # Use 'categorical' for multiple classes\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = keras.Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3),\n",
        "           data_format=\"channels_last\"),  # Input layer with Conv2D\n",
        "    MaxPooling2D(2, 2),  # Max-pooling layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Second Conv2D layer\n",
        "    MaxPooling2D(2, 2),  # Second Max-pooling layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),  # Third Conv2D layer\n",
        "    MaxPooling2D(2, 2),  # Third Max-pooling layer\n",
        "    Flatten(),  # Flatten layer\n",
        "    Dense(512, activation='relu'),  # Dense (fully connected) layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,  # You can adjust the number of epochs\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('lump_detection_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhXaq6HVdxfG",
        "outputId": "7829ce7b-2800-418a-a8a3-c765145d05a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 949 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "30/30 [==============================] - 64s 2s/step - loss: 0.8236 - accuracy: 0.5364\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.5943 - accuracy: 0.6702\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 59s 2s/step - loss: 0.4830 - accuracy: 0.7671\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 61s 2s/step - loss: 0.4147 - accuracy: 0.8230\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 62s 2s/step - loss: 0.3929 - accuracy: 0.8367\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.4749 - accuracy: 0.7893\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 64s 2s/step - loss: 0.4031 - accuracy: 0.8230\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.3320 - accuracy: 0.8588\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 65s 2s/step - loss: 0.2906 - accuracy: 0.8757\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 66s 2s/step - loss: 0.2622 - accuracy: 0.9009\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 66s 2s/step - loss: 0.2376 - accuracy: 0.9062\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 64s 2s/step - loss: 0.2516 - accuracy: 0.8904\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 66s 2s/step - loss: 0.1943 - accuracy: 0.9283\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 69s 2s/step - loss: 0.2216 - accuracy: 0.9062\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 64s 2s/step - loss: 0.1980 - accuracy: 0.9231\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 59s 2s/step - loss: 0.2022 - accuracy: 0.9178\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 61s 2s/step - loss: 0.1469 - accuracy: 0.9420\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.1457 - accuracy: 0.9526\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 62s 2s/step - loss: 0.1404 - accuracy: 0.9484\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.1246 - accuracy: 0.9547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained model in H5 format\n",
        "model_path = '/content/lump_detection_model.h5'  # Replace with the path to your H5 model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Convert the model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_path = 'lump_eye.tflite'  # Replace with the desired path for the TFLite model\n",
        "with open(tflite_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"Model converted and saved to {tflite_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY40CeKHkGEH",
        "outputId": "5f6cb6c5-8d63-4567-cb1a-af6cb5b43047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model converted and saved to lump_eye.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTING**"
      ],
      "metadata": {
        "id": "Td_YtVvNl6RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the testing data from the zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/lump eye/Lump Test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('testing_data')"
      ],
      "metadata": {
        "id": "kFe3JUoeHAWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import os\n",
        "\n",
        "# Load the TensorFlow Lite model\n",
        "tflite_model_path = '/content/lump_eye.tflite'  # Replace with the path to your .tflite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Define the path to the extracted test dataset directory\n",
        "test_dir = '/content/testing_data'\n",
        "\n",
        "# Initialize variables to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the images in the test dataset\n",
        "for subdir, _, files in os.walk(test_dir):\n",
        "    for file in files:\n",
        "        image_path = os.path.join(subdir, file)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        image = load_img(image_path, target_size=(150, 150))\n",
        "        image = img_to_array(image) / 255.0  # Normalize the image\n",
        "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Perform inference using the TFLite model\n",
        "        interpreter.set_tensor(input_details[0]['index'], image)\n",
        "        interpreter.invoke()\n",
        "        tflite_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        # Store true and predicted labels\n",
        "        true_labels.append(1 if 'lump' in subdir.lower() else 0)\n",
        "        predicted_labels.append(tflite_predictions[0][0])\n",
        "\n",
        "# Convert the lists to numpy arrays for comparison\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "threshold = 0.5  # Threshold for binary classification\n",
        "predicted_classes = (predicted_labels >= threshold).astype('int32')\n",
        "correct_predictions = np.sum(predicted_classes == true_labels)\n",
        "accuracy = correct_predictions / len(true_labels)\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFmIH0Rkl9SX",
        "outputId": "e81916e4-c5c1-4a1c-a530-e2b10ca28f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 50.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM**"
      ],
      "metadata": {
        "id": "Qr0qG0jmmiFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np  # Import NumPy\n",
        "# Load the TFLite model\n",
        "tflite_path = '/content/lump_eye.tflite'  # Replace with the path to your TFLite model\n",
        "interpreter = interpreter_wrapper.Interpreter(model_path=tflite_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Define the path to the folder containing mixed lump and normal images\n",
        "image_folder = '/content/drive/MyDrive/lump eye/test random'  # Replace with the path to your image folder\n",
        "\n",
        "# Create empty lists to store lump and normal image filenames\n",
        "lump_images = []\n",
        "normal_images = []\n",
        "\n",
        "# Iterate over the images in the folder and classify them\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(image_path)\n",
        "        image = image.resize((150, 150))  # Resize to match the model's input size\n",
        "        image = tf.convert_to_tensor(image, dtype=tf.float32) / 255.0  # Normalize the image\n",
        "        image = image.numpy()\n",
        "        image = image[np.newaxis, ...]  # Add a batch dimension\n",
        "\n",
        "        # Set input tensor\n",
        "        input_details = interpreter.get_input_details()\n",
        "        interpreter.set_tensor(input_details[0]['index'], image)\n",
        "\n",
        "        # Invoke the interpreter\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Get the output tensor\n",
        "        output_details = interpreter.get_output_details()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        # Classify the image\n",
        "        is_lump = output[0][0] > 0.5  # Adjust the threshold as needed\n",
        "\n",
        "        # Separate lump and normal images\n",
        "        if is_lump:\n",
        "            lump_images.append(filename)\n",
        "        else:\n",
        "            normal_images.append(filename)\n",
        "\n",
        "# Display the lump and normal image filenames\n",
        "print(\"Lump Images:\")\n",
        "for filename in lump_images:\n",
        "    print(filename)\n",
        "\n",
        "print(\"\\nNormal Images:\")\n",
        "for filename in normal_images:\n",
        "    print(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yZ3ebVemnB9",
        "outputId": "51c5b770-2c92-4fb8-9164-69b3eac96efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lump Images:\n",
            "AA (9).jpg\n",
            "AA (4).jpg\n",
            "AA (7).jpg\n",
            "AA (6).jpg\n",
            "AA (8).jpg\n",
            "AA (5).jpg\n",
            "AA (3).jpg\n",
            "AA (20).jpg\n",
            "AA (14).jpg\n",
            "AA (13).jpg\n",
            "AA (1).jpg\n",
            "AA (11).jpg\n",
            "AA (15).jpg\n",
            "AA (10).jpg\n",
            "AA (16).jpg\n",
            "AA (19).jpg\n",
            "AA (2).jpg\n",
            "AA (18).jpg\n",
            "AA (17).jpg\n",
            "AA (12).jpg\n",
            "\n",
            "Normal Images:\n",
            "BB (1).png\n",
            "BB (9).png\n",
            "BB (8).png\n",
            "BB (5).png\n",
            "BB (4).png\n",
            "BB (6).png\n",
            "BB (7).png\n",
            "BB (20).png\n",
            "BB (19).png\n",
            "BB (3).png\n",
            "BB (2).png\n",
            "BB (18).png\n",
            "BB (17).png\n",
            "BB (16).png\n",
            "BB (15).png\n",
            "BB (13).png\n",
            "BB (14).png\n",
            "BB (12).png\n",
            "BB (10).png\n",
            "BB (11).png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the TFLite model\n",
        "tflite_path = '/content/drive/MyDrive/lump eye/lump_eye.tflite'  # Replace with the path to your TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Define a function to classify an image\n",
        "def classify_image(image_path):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((150, 150))  # Resize to match the model's input size\n",
        "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize the image\n",
        "    image = np.expand_dims(image, axis=0)  # Add a batch dimension\n",
        "\n",
        "    # Set input tensor\n",
        "    input_details = interpreter.get_input_details()\n",
        "    interpreter.set_tensor(input_details[0]['index'], image)\n",
        "\n",
        "    # Invoke the interpreter\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor\n",
        "    output_details = interpreter.get_output_details()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Classify the image\n",
        "    is_lump = output[0][0] > 0.5  # Adjust the threshold as needed\n",
        "\n",
        "    # Return the classification result\n",
        "    return \"Lump eye\" if is_lump else \"Normal eye\"\n",
        "\n",
        "# Define the path to the image you want to classify\n",
        "image_to_classify = '/content/download.jfif'  # Replace with the path to your image\n",
        "\n",
        "# Classify the image\n",
        "result = classify_image(image_to_classify)\n",
        "print(f\"The image is classified as: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY3xFJzho6UK",
        "outputId": "2d749871-1f93-43eb-ecc7-fe6238e47ef1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image is classified as: Normal eye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NEW TRAINING**"
      ],
      "metadata": {
        "id": "Bx3M-r9w69HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the data from the zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/lump eye/LUMP train 2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('lump_images')"
      ],
      "metadata": {
        "id": "ZrH6miNy7gsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the paths to your data\n",
        "train_dir = '/content/lump_images'  # Update this path\n",
        "\n",
        "\n",
        "\n",
        "# Create an image data generator\n",
        "train_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,  # Adjust rotation range to simulate different lash angles\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],  # Adjust brightness to highlight lashes\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_data_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Adjust the image size as needed\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # Use 'categorical' for multiple classes\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = keras.Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3),\n",
        "           data_format=\"channels_last\"),  # Input layer with Conv2D\n",
        "    MaxPooling2D(2, 2),  # Max-pooling layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Second Conv2D layer\n",
        "    MaxPooling2D(2, 2),  # Second Max-pooling layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),  # Third Conv2D layer\n",
        "    MaxPooling2D(2, 2),  # Third Max-pooling layer\n",
        "    Flatten(),  # Flatten layer\n",
        "    Dense(512, activation='relu'),  # Dense (fully connected) layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,  # You can adjust the number of epochs\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('lump_detection_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHM1hSfW67fy",
        "outputId": "65b666fa-3e97-4f06-9fc0-70fcfad11d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 470 images belonging to 1 classes.\n",
            "Epoch 1/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0484 - accuracy: 0.9319\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 35s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 27s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 27s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 27s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 29s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 25s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 27s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 27s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model in H5 format\n",
        "model_path = '/content/lump_detection_model.h5'  # Replace with the path to your H5 model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Convert the model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_path = 'lump_eye-2.tflite'  # Replace with the desired path for the TFLite model\n",
        "with open(tflite_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"Model converted and saved to {tflite_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3cPs83ZACdX",
        "outputId": "7018f330-ec66-46a2-e977-1e508dd52e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model converted and saved to lump_eye-2.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def classify_single_image(image_path, tflite_model_path):\n",
        "    # Load the TFLite model\n",
        "    interpreter = interpreter_wrapper.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((150, 150))  # Resize to match the model's input size\n",
        "    image = np.array(image, dtype=np.float32) / 255.0  # Normalize the image\n",
        "    image = np.expand_dims(image, axis=0)  # Add a batch dimension\n",
        "\n",
        "    # Set input tensor\n",
        "    input_details = interpreter.get_input_details()\n",
        "    interpreter.set_tensor(input_details[0]['index'], image)\n",
        "\n",
        "    # Invoke the interpreter\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor\n",
        "    output_details = interpreter.get_output_details()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Classify the image\n",
        "    is_lump = output[0][0] > 0.5  # Adjust the threshold as needed\n",
        "\n",
        "    # Return classification result\n",
        "    return \"Lump\" if is_lump else \"Normal\"\n",
        "\n",
        "# Replace with the path to your single image\n",
        "image_to_classify = '/content/zain.jpg'\n",
        "\n",
        "# Replace with the path to your TFLite model\n",
        "model_path = '/content/lump_eye.tflite'\n",
        "\n",
        "result = classify_single_image(image_to_classify, model_path)\n",
        "print(f\"The image is classified as: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmpScQC5EBUj",
        "outputId": "c6dce8c2-8441-433b-c500-c871a67699e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image is classified as: Normal\n"
          ]
        }
      ]
    }
  ]
}